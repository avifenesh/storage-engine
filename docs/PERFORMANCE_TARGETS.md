# ðŸŽ¯ Performance Targets â€” Columnar Database

## Overview
Realistic, measurable targets for a userspace columnar database built iteratively. Focus on correctness first; measure p50/p99 and publish simple, repeatable results.

## Core Metrics

### Hash Engine (userspace)
| Metric | Target | Notes |
|--------|--------|-------|
| Put ops/s | â‰¥ 3k (1 thread), â‰¥ 15k (8 threads) | ~0.7 load factor |
| Get ops/s | â‰¥ 10k (1 thread), â‰¥ 50k (8 threads) | uniform keys |
| Memory overhead | â‰¤ 1.5Ã— payload | at ~0.7 load |
| p99 probe length | â‰¤ 8 | linear probing |

### B+ Tree (userspace)
| Metric | Target | Notes |
|--------|--------|-------|
| Lookup ops/s | publish p50/p99 | balanced height |
| Range scan throughput | publish p50/p99 | leaf traversal |
| Node occupancy | â‰¥ 60% average | steadyâ€‘state |

### Page/Buffer + WAL
| Metric | Target | Notes |
|--------|--------|-------|
| Cache hit/miss | publish and compare | controlled workloads |
| Flush latency | bounded; published | fsync grouping |
| Recovery | passes crashâ€‘injection | reproducible harness |

## Sprintâ€‘Specific Targets

### Sprint 2: Hash (Userspace)
- Property tests (100k ops); p99 probe length â‰¤ 8 at ~0.7 load
- Publish get/put ops/s (1 thread, 8 threads) and memory overhead

### Sprint 3: B+ Tree (Userspace)
- Invariants validated; iterators and range scans; p50/p99 reported

### Later Sprints (Page/Buffer, WAL, Vectorized Exec)
- Cache stats, flush latencies, recovery harness results
- Vectorized scans show â‰¥ 3Ã— over tupleâ€‘atâ€‘aâ€‘time on simple predicates

## Methodology
- Warm up and measure steady state
- Pin threads to cores when comparing runs
- Record hardware/kernel versions in metrics.json
- Use perf/ftrace/flamegraphs for hotspots and ASan/Valgrind for memory

## Gates
### Must Have
- âœ… Correctness via tests/property tests
- âœ… Memoryâ€‘safe (ASan/Valgrind clean)
- âœ… Published p50/p99 and environment notes

### Should Have
- âœ… SIMD speedups when enabled
- âœ… Scaling with thread count (contention understood)
- âœ… Clear performance documentation

### Notes
Hash table lookups are O(1) on average; vectorized scans reduce perâ€‘tuple overhead; WAL with fsync grouping can bound flush latency. Focus on clarity, measurement, and incremental improvement.

